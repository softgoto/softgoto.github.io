---
title: ELK7.6.2部署教程
date: 2020-06-10 16:09:34
categories: 技术类
tags:
- ELK
- Elasticsearch
- Logstash
- Kibana
- Filebeat
- Metricbeat
---

### 前言

ELK 到底是什么？下面引用官网的解释。

> “ELK”是三个开源项目的首字母缩写，这三个项目分别是：Elasticsearch、Logstash 和 Kibana。Elasticsearch 是一个搜索和分析引擎。Logstash 是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等“存储库”中。Kibana 则可以让用户在 Elasticsearch 中使用图形和图表对数据进行可视化。

除了 Elasticsearch、Logstash 和 Kibana 之外，我们还需要 Filebeat 和 Metricbeat，这两个组件都属于 Beats 系列中的采集器（Beats 是一些列的轻量级数据采集器）；Filebeat 主要负责采集日志文件，在教程中我们使用它来采集应用系统的日志文件。Metricbeat 主要负责采集指标数据，在教程中我们用它来采集ELKF组件的指标数据来监控各个组件的运行情况。

本次教程中用到的服务器是 CentOS 7.4，用到的安装包是从 [ELK官网地址](https://www.elastic.co) 找到对应的产品，选择对应的版本下载。

附上一张 ELK 高可用的架构图，下面我们开始搭建 ELK

<!--more-->

![Snipaste_2020-05-06_13-30-47.png](https://i.loli.net/2020/05/06/Z6HVrS89DqPujlE.png)

### Elasticsearch（单节点模式）

#### 准备工作

Elasticsearch 7.x 自带 OpenJDK11，可以指定 Oracle JDK，但版本必须在 1.8 及以上。在配置好 Java 环境之后，启动时会使用系统配置的 Java 环境。在安装 Elasticsearch 时，需要在服务器创建一个新的用户，因为 Elasticsearch 在启动时不支持 root 用户启动。

#### 解压&配置

切换到新创建的用户并将安装文件 `elasticsearch-7.6.2-linux-x86_64.tar.gz` 上传到服务器，然后解压文件 & 修改配置

```shell
$ tar -xvf elasticsearch-7.6.2-linux-x86_64.tar.gz

$ cd elasticsearch-7.6.2/config

$ vim elasticsearch.yml
```

找到 `node.name: node-1` 配置行，删除前面的#号

找到 `network.host: 192.168.0.1` 配置行，复制后将配置改成 `network.host: 0.0.0.0`，`0.0.0.0` 表示本机 IP。

在配置文件最后一行添加下面的配置

> xpack 是 ELK 的安全认证框架，包括 TLS 通讯加密、创建和管理用户、基于角色的访问控制等功能。原本是付费的功能，但在19年5月 Elastic 官方宣布 6.8.0 和 7.x 版本核心功能免费。

```yaml
# 开启xpack安全认证
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true

# 单节点模式
discovery.type: single-node
```

另外，默认的数据存储目录、日志存放目录和服务默认端口配置也说明一下

```yaml
# 数据存储目录，默认在 elasticsearch-7.6.2/data
path.data: /path/to/data

# 日志存储目录，默认在 elasticsearch-7.6.2/logs
path.logs: /path/to/logs

# 服务端口，默认 9200
http.port: 9200
```

#### 配置优化

1、根据实际情况调整 JVM 配置

需要注意的是单节点最大内存配置要小于 `32G`，合理配置为 `31G`。ES有个内存指针压缩技术，JVM 小于 `32G` 才会开启内存压缩，并且 JVM 内存过大会导致重启节点耗费时间太久，JVM 垃圾回收时间过长，容易导致节点脱离集群。

```shell
$ vim elasticsearch-7.6.2/config/jvm.options

-Xms12g  # 这里根据自己服务器的内存大小自由发挥
-Xmx12g  # 这里根据自己服务器的内存大小自由发挥
```

2、修改系统允许的最大文件打开数

```shell
# 先查看服务器目前的 open files
$ ulimit -a

# 修改 open files
$ sudo vim /etc/security/limits.conf

*   soft  nofile   20480
*   hard  nofile   20480

# 其中 * 表示所有用户 nofile 表示最大文件句柄数，表示能够打开的最大文件数目
```

#### 启动

```shell
# 后台启动
$ ./bin/elasticsearch -d
```

#### 初始化密码

因为前面配置开启了 xpack 功能，所以需要初始化一次密码

```shell
$ ./bin/elasticsearch-setup-passwords interactive
```

这里会把 Elasticsearch、Kibana、Logstash 等组件的密码一起设置了，**建议密码配置成同一个**

#### 验证

打开浏览器访问 `http://[你服务器的IP]:9200`，会弹出一个输入账号密码的提示框，在账号栏输入 `elastic` 密码栏输入上一步设置的密码，页面能出现类似下面的 JSON 内容就正常了。

```json
{
  "name" : "node-1",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "PDqu_1JrRraoBsMBZ3Kfdw",
  "version" : {
    "number" : "7.6.2",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "ef48eb35cf30adf4db14086e8aabd07ef6fb113f",
    "build_date" : "2020-03-26T06:34:37.794943Z",
    "build_snapshot" : false,
    "lucene_version" : "8.4.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
```

#### 启动常见错误

1、max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]

原因：系统最大文件打开数配置太小
解决：编辑 `/etc/security/limits.conf` 文件（需要 root 权限），增加下面配置

```shell
*   soft  nofile   65536
*   hard  nofile   65536
```

2、max number of threads [3818] for user [es] is too low, increase to at least [4096]

原因：系统最大线程个数配置太小
解决：编辑 `/etc/security/limits.conf` 文件（需要 root 权限），增加下面配置

```shell
*   soft  nproc   4096
*   hard  nproc   4096
```

3、max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]

原因：最大虚拟内存配置太低
解决：编辑 `/etc/sysctl.conf` 文件（需要 root 权限），增加下面配置

```shell
vm.max_map_count=262144

# 执行命令使配置生效
$ sysctl -p
```

### Logstash

如果 Logstash 和 Elasticsearch 分别安装在不同的机器，我还是建议使用非 root 用户安装。将安装文件 `logstash-7.6.2.tar.gz` 上传到服务器，然后解压文件 & 修改配置

#### 解压&配置

解压文件

```shell
$ tar -xvf logstash-7.6.2.tar.gz
$ cd logstash-7.6.2/config/
```

修改 `logstash.yml` 配置文件

```shell
$ vim logstash.yml
```

```yaml
# 开启监控设置（后面Metricbeat用到）
http.host: "0.0.0.0"
http.port: 9600

# 开启xpack，配置ES的账号密码，在前面初始化ES密码的时候，有一个logstash_system的用户
xpack.management.elasticsearch.username: logstash_system
xpack.management.elasticsearch.password: ES初始化密码的时候填的密码
xpack.management.elasticsearch.hosts: ["https://[ES节点的IP]:9200"]
```

修改 `jvm.options` 配置文件

```shell
$ vim jvm.options

-Xms12g  # 这里根据自己服务器的内存大小自由发挥
-Xmx12g  # 这里根据自己服务器的内存大小自由发挥
```

复制 `logstash-sample.conf` 文件，编写过滤规则

```shell
$ cp logstash-sample.conf logstash-ng-app-log.conf
$ vim logstash-ng-app-log.conf
```

```yaml
########################################################################################################
######                                         配置示例                                            ######
######            Logstash在创建索引时规则是：logstash-%{[fields][appname]}-%{+YYYY.MM.dd}          ######
######                   在采集端Filebeat配置时，需要增加appname字段，与工程名保持相同                ######
######                               比如：nginx、usercenter、marketcenter                         ######
########################################################################################################

# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][appname] == "nginx" {
    mutate {
      # 替换NG日志中UserAgent中可能出现的中文转义字符（如果不处理 Logstash 解析报错：Unrecognized character escape 'x'）
      gsub => ["message", "\\x", "\\\x"]
    }
    json {
      source => "message"
      # target => "doc"
      # remove_field => ["message"]
    }
    geoip {
      source => "remote_addr"
      target => "geoip"
      # 使用 GeoLite2-City 库解析IP，将 IP 转换成城市名。库从这里下载 https://dev.maxmind.com/geoip/geoip2/geolite2/
      # 下载后上传到服务器，在下面配置指向数据库文件就可以了
      database => "/home/user/logstash-7.2.6/geolite2db/GeoLite2-City.mmdb"
      add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
      add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}" ]
    }
  }else{
    grok {
      # 匹配日志时间
      match => {"message" => "(?<timestamp>^([0-9]+-[0-9]+-[0-9]+\s[0-9]+:[0-9]+:[0-9]+,[0-9]+))"}
    }
    grok {
      # 匹配日志级别，输出到 level 字段
      match => {"message" => "%{LOGLEVEL:level}"}
    }
    date {
      # 将上面日志时间格式之后覆盖到 @timestamp
      match => ["timestamp", "yyyy-MM-dd HH:mm:ss,SSS"]
      target => "@timestamp"
    }
    mutate {
      remove_field => ["timestamp"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://youer-es-ip:9200"]
    index => "logstash-%{[fields][appname]}-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "******" # 前面自己配置的密码
  }
}
```

#### 启动

1、先检查配置文件编写是否正确

```shell
$ ./bin/logstash -t -f config/logstash-ng-app-log.conf
```

看到 `Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash` 表示配置文件正常

2、后台启动

```shell
$ nohup ./bin/logstash -f config/logstash-ng-app-log.conf &

# 或者这样（动态配置加载模式，配置文件如果有变化会自动重新加载）
$ nohup ./bin/logstash -f config/logstash-ng-app-log.conf --config.reload.automatic &
```

### Kibana

如果 Kibana 和上面其他组件分别安装在不同的机器，我还是建议使用非 root 用户安装。将安装文件 `kibana-7.6.2-linux-x86_64.tar.gz` 上传到服务器，然后解压文件 & 修改配置

#### 解压&配置

解压文件

```shell
$ tar -xvf kibana-7.6.2-linux-x86_64.tar.gz
$ cd kibana-7.6.2-linux-x86_64
```

修改 `kibana.yml` 配置文件

```shell
$ vim config/kibana.yml
```

```yaml
# 服务端口
server.port: 5601

# 本机IP
server.host: "192.168.100.190"

# ES 服务地址
elasticsearch.hosts: ["http://192.168.100.192:9200"]

# 账号密码，前面在安装ES时生成的密码
elasticsearch.username: "kibana"
elasticsearch.password: "********"

# 语言: 默认英文 en 中文 zh-CN
i18n.locale: "zh-CN"
```

#### 启动

后台启动

```shell
$ nohup ./bin/kibana &
```

### Filebeat

将安装文件 `filebeat-7.6.2-linux-x86_64.tar.gz` 上传到服务器，然后解压文件 & 修改配置

#### 解压&配置

解压文件

```shell
$ tar -xvf filebeat-7.6.2-linux-x86_64.tar.gz
$ cd filebeat-7.6.2-linux-x86_64
```

修改 `filebeat.yml` 配置

```shell
$ vim filebeat.yml
```

```yaml
filebeat.inputs:

- type: log

  enabled: true

  paths:
    - /data/logs/mop-prd-user/*.log

  fields:
    appname: usercenter

  # 多行合并
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml

  reload.enabled: false

setup.template.settings:
  index.number_of_shards: 1

setup.kibana:

output.logstash:
  hosts: ["Logstash的IP:5044"]

processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

# 开启http endpoint
http.enabled: true
http.host: 本机IP
http.port: 5066
```

#### 启动

后台启动

```shell
$ nohup ./filebeat -e -c filebeat.yml -d "publish" &
```

### Metricbeat

将安装文件 `filebeat-7.6.2-linux-x86_64.tar.gz` 上传到服务器，然后解压文件 & 修改配置

#### 解压&配置

解压文件

```shell
$ tar -xvf metricbeat-7.6.2-linux-x86_64.tar.gz
$ cd metricbeat-7.6.2-linux-x86_64
```

修改 `metricbeat.yml` 配置

```shell
$ vim metricbeat.yml
```

```yaml
metricbeat.config.modules:
  path: ${path.config}/modules.d/*.yml

  reload.enabled: false

setup.template.settings:
  index.number_of_shards: 1
  index.codec: best_compression


setup.kibana:


output.elasticsearch:
  hosts: ["192.168.100.192:9200"]

  # 前面配置的账号密码
  username: "elastic"
  password: "********"


processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

```

启用要采集的组件模块

```shell
# 如果ELK开启了xpack，则这里就需要带xpack
$ ./metricbeat modules enable kibana-xpack elasticsearch-xpack logstash-xpack beat-xpack
```

禁用模块

```shell
$ ./metricbeat modules disable system
```

初始化索引模板和dashboards（可选）

```shell
$ ./metricbeat setup
```

#### 启动

后台启动

```shell
$ nohup ./metricbeat -e &
```


Done. :coffee: